---
title: "Exploratory analysis of the results of applying machine-learning models across Library of Congress digital collections "
subtitle: "Computing Cultural Heritage in the Cloud"
author: "Lincoln Mullen"
date: "January 2022"
output: pdf_document
urlcolor: blue
---

```{r setup, include=FALSE}
library(DBI)
library(tidyverse)
library(dbplyr)

knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

```{r connect}
db <- dbConnect(odbc::odbc(), "CCHC", timeout = 10)
```

```{r helpers}
pnum <- function(x) { prettyNum(as.integer(x), ",") }
```

This report is a part of the extension of the [*America's Public Bible*](https://americaspublicbible.org) project for the [Computing Cultural Heritage in the Cloud](https://labs.loc.gov/work/experiments/cchc/) initiative. Please see the [GitHub repository](https://github.com/lmullen/cchc) for the project for full details about how these datasets were created.

The purpose of this report is to demonstrate the viability of the initial results of applying machine learning models to Library of Congress full-text digtal collections. Full interpretative findings, which are outside the specific scope of the project, will subsequently be published on the *America's Public Bible* website or other suitable publication venues.

## Creation of the dataset

The two datasets used in this report were created in November 2021 through January 2022 by applying machine-learning models to a subset of Library of Congress digital collections. This subset was (1) items that were part of collections identified by subject as pertaining to American history; (2) items that were marked in the library catalog has having full text available; (3) items for which that full text could be readily identified and accessed. 

Two datasets were created. One, generated by the `cchc-language-detector` service, seeks to identify multilingual items in the collections. The other, generated by the `ccch-predictor` service, seeks to identify biblical quotations in the English language collections.

## Language detection dataset


```{r}
lang_tbl <- tbl(db, in_schema("results", "languages")) |> 
  select(-job_id)
lang <- lang_tbl |> 
  group_by(item_id) |> 
  mutate(percentage = round(sentences / as.numeric(sum(sentences, na.rm = TRUE)), 3))
```

```{r}
# How many unique items are we talking about?
num_lang_items <- lang_tbl |> distinct(item_id) |> count() |> pull(n)
```

For evaluation purposes the language detector was run over a limited subset of `r pnum(num_lang_items)` items. Note that items can include many additional resources: in some instances, thousands of pages or sub-items.

The language detector works by splitting each page or resource into sentences, detecting the language of that sentence, and calculating the total number of sentences in each language. 

As an example of what this data looks like, let us consider a single item, identified in the loc.gov API by its URL: <http://www.loc.gov/item/00002075/>. For the purposes of preserving the conditions of computational research, where it is not possible to examine each item individually, let us delay looking up the item's title. It is sufficient to know that the loc.gov API can report multiple languages for each item, and that it reports this item's language as "English." Here are the raw results for this item:

```{r}
test_lang_item <- lang |> 
  filter(item_id == "http://www.loc.gov/item/00002075/") |> 
  arrange(desc(sentences)) 
test_lang_item |> knitr::kable()
```
Each row shows the language code (represented according to [ISO 632-2](https://www.loc.gov/standards/iso639-2/php/code_list.php)), the count of the sentences in that language, and the percentage of the total number of sentences in that language. Tokenization into sentences is not perfect, and because sentences can be quite short, language detection will not work on every sentence.^[See the [go-linguage documentation](https://github.com/pemistahl/lingua-go) for details.] When the underlying library determines that the "sentence" is too short to classify, it reports the language as `UND`, or "undetermined." Given the short length of many sentences, we should also expect false positives, especially in lengthy documents like this one. Clearly that is the case in this instance: a document containing 44 languages running from Afrikaans to Zulu is, shall we say, improbable. 

Nevertheless, the purpose of this detector is _not_ to identify specific languages at the sentence level, but to identify multilingual documents at the item level. We can easily set a coarse filter to eliminate the majority of false positives. Let us set some common sense filters, which can be refined later. We can eliminate any languages as potential false positives if they meet any of the following conditions:

- Already marked as `UND` (undetermined)
- There are 2 or fewer sentences in that language in a document
- The language comprises less than 3% of a document.

```{r}
filter_langs <- function(x) {
  x |>  filter(lang != "UND", sentences > 2, percentage > 0.03)
}
```

Using these common sense tests, we can eliminate potential false positives from our sample item. 

```{r}
test_lang_item |> filter_langs() |> knitr::kable()
```
In other words, the loc.gov API tell us that this document is in English. We have found that it is predominantly in English, but with substantial portions in Italian, Icelandic, and French.

Does this result hold up upon [inspecting the item](https://www.loc.gov/item/00002075/)? The item's title is "Dancing and its relations to education and social life with a new method of instruction, including a complete guide to the cotillion (German) with 250 figures." The subject matter and skimming the document make it extremely probable that the document contains substantial portions in French and Italian. We might note two potential defects in the language detector. Icelandic is represented as the third most common language, but this seems unlikely. The language detector uses every language that it knows about, but perhaps Icelandic should be eliminated from consideration at the detector level. Likewise, the item's title mentions that the cotillion is German. Was German used in the document? It is not a foregone conclusion that it should have been, but it would be worth checking.

Nevertheless, the results of our coarse, common sense filter are so far promising for identifying multilingual documents.

```{r}
lang_keepers <- lang |> 
  filter_langs() |> 
  count(item_id) |> 
  filter(n > 1) |> 
  collect()
num_possible_multilingual <- lang_keepers |> nrow()
```

Let us apply this technique to all of the items for which we have calculated language statistics. We find that we identify `r pnum(num_possible_multilingual)` possible multilingual documents. 

```{r}
api_multi <- dbGetQuery(db, "select id AS item_id FROM items WHERE array_length(languages, 1) > 1 ;") 

not_in_api <- lang_keepers |>  anti_join(api_multi, by = "item_id") 
```

We can compare those to results to the list of multilingual documents reported by the loc.gov API. We find that `r pnum(nrow(not_in_api))` of our potential multilingual items, or all but five, are not reported as multilingual by the API. It is of course possible that our coarse filter ought to be yet more coarse, but this does seem to indicate the possibility of multilingual documents not identified as such in the catalog.

As a final step for this report, we can consider unique combinations of languages. Using our estimates, which languages appear together in the most number of items. Note that this listing arranges the languages alphabetically, not according to their predominance in a document. Limiting this to the top 50 combinations of languages, we find the following:

```{r}
lang |> 
  filter_langs() |> 
  filter(n() > 1) |> 
  arrange(item_id, lang) |>
  collect() |> 
  ungroup() |> 
  group_by(item_id) |> 
  summarize(lang_combo = str_c(lang, collapse = ", ")) |> 
  group_by(lang_combo) |> 
  count(sort = TRUE) |> 
  rename(num_items = n) |> 
  head(50) |> 
  knitr::kable()
```

Some of the combinations are prima facie extremely likely. The first combination (English and Latin) and the third combination (English and French) make perfect sense. Other combinations, including English and Welsh (`CYM`) raise some questions. If, upon inspection of the items Welsh is not being accurately detected, perhaps it should be eliminated from the language detector. Alternatively, it is possible that the parameters for our filter described above should be more restrictive to avoid even more false positives.

While further analysis and inspection is necessary, my cautious conclusion is that these preliminary results validate the process of identifying potential multilingual documents computationally.

```{r disconnect}
dbDisconnect(db)
```

